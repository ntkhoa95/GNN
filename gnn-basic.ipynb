{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Author: Niko\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.31.0\n",
      "\n",
      "torch: 1.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Niko' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Basic Graph Neural Network with Gaussian Filter on MNIST\n",
    "\n",
    "A very basic graph neural network (GNN) implementation using a Gaussian Filter.\n",
    "\n",
    "<br>Here, the 28x28 image of a digit in MNIST represents the graph, where each pixel (i.e., cell in the grid) represents a particular node. The feature of that node is simply the pixel intensity in range [0, 1].\n",
    "\n",
    "<br>The adjacency matrix of the pixels is basically just determined by their neighborhood pixels. Using a Gaussian filter, we connect pixels based on their Euclidean distance in grid.\n",
    "\n",
    "<br>Using this adjacency matrix A, we can compute the output of a layer as\n",
    "\\begin{align*}\n",
    "X^{(l+1)} = AX^{(l)}W^{(l)}\n",
    "\\end{align*}\n",
    "\n",
    "Here, A is the N x N adjacency matrix, and X is the N x C feature matrix (a 2D coordinate array, where N is the total number of pixels -- 28 x 28 = 784 in MNIST).\n",
    "W is the weight matrix of shape N x P, where P would present the number of classes if we have only a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time, torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataset import Subset\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings, copy\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Setting hyper-parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transfrom = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=custom_transfrom, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=custom_transfrom, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean, std = torch.zeros(3), torch.zeros(3)\n",
    "# for img, label in train_dataset:\n",
    "#     mean += torch.mean(img, dim=(1, 2))\n",
    "#     std  += torch.std(img, dim=(1, 2))\n",
    "    \n",
    "# mean /= len(train_dataset)\n",
    "# std /= len(train_dataset)\n",
    "\n",
    "# mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimension:  torch.Size([128, 1, 28, 28])\n",
      "Image label dimension:  torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "SPLIT_RATIO = 0.9 # 80% for training, 20% for valid\n",
    "train_samples_num = int(len(train_dataset) * SPLIT_RATIO)\n",
    "val_samples_num = len(train_dataset) - train_samples_num\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_samples_num, val_samples_num])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
    "val_loader   = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
    "\n",
    "# Check the dataset\n",
    "for images, labels in train_loader:\n",
    "    print('Image batch dimension: ', images.shape)\n",
    "    print('Image label dimension: ', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_adjacency_matrix(img_size):\n",
    "    col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
    "    \n",
    "    # N = img_size x img_size\n",
    "    # Construct a 2D coordinate array (shape N x 2) and normalize to range (0, 1)\n",
    "    coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
    "\n",
    "    # Compute pairwise distance matrix (N x N)\n",
    "    dist = cdist(coord, coord, metric='euclidean')\n",
    "\n",
    "    # Apply Gaussian Filter\n",
    "    sigma = 0.05 * np.pi\n",
    "    A = np.exp(-dist / sigma**2)\n",
    "    A[A < 0.01] = 0\n",
    "    A = torch.from_numpy(A).float()\n",
    "\n",
    "    # Normalization as per (Kipf & Welling, ICLR 2017)\n",
    "    D = A.sum(1) # nodes degree (N,)\n",
    "    D_hat = (D + 1e-5)**(-0.5)\n",
    "    A_hat = D_hat.view(-1, 1) * A * D_hat.view(1, -1)\n",
    "\n",
    "    return A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 784])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_hat = precompute_adjacency_matrix(28)\n",
    "print(A_hat.shape)\n",
    "plt.imshow(precompute_adjacency_matrix(28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Model\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, img_size=28, num_classes=10):\n",
    "        super(GraphNet, self).__init__()\n",
    "\n",
    "        n_rows = img_size**2\n",
    "        self.fc = nn.Linear(n_rows, num_classes, bias=False)\n",
    "        A = precompute_adjacency_matrix(img_size=img_size)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0) # Batch size\n",
    "\n",
    "        # Reshape Adjacency Matrix\n",
    "        # [N, N] Adjacency. matrix -> [1, N, N] Adjacency tensor where N = H x W\n",
    "        A_tensor = self.A.unsqueeze(0)\n",
    "        A_tensor = self.A.expand(B, -1, -1)\n",
    "\n",
    "        # Reshape inputs\n",
    "        # [B, C, H, W] -> [B, HxW, 1]\n",
    "        x_reshape = x.view(B, -1, 1)\n",
    "\n",
    "        # bmm: batch matrix product to sum the neighbor features\n",
    "        # Input: [B, N, N] x [B, N, 1]\n",
    "        # Output: [B, N]\n",
    "        avg_neighbor_features = torch.bmm(A_tensor, x_reshape).view(B, -1)\n",
    "        logits = self.fc(avg_neighbor_features)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = GraphNet(img_size=IMG_SIZE, num_classes=10)\n",
    "model = model.to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, dataloader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for features, targets in dataloader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, pred_labels = torch.max(probas, 1)\n",
    "        num_examples += features.size(0)\n",
    "        correct_pred += (pred_labels == targets).sum()\n",
    "    return correct_pred.float() / num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 |Batch: 000/422 |Loss: 2.3130\n",
      "Epoch: 001/020 |Batch: 150/422 |Loss: 0.4439\n",
      "Epoch: 001/020 |Batch: 300/422 |Loss: 0.2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:05<01:46,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020\n",
      "Train Accuracy: 90.59 | Valid Accuracy: 89.67 | Test Accuracy: 90.55\n",
      "Time elapsed: 0.09 min\n",
      "Epoch: 002/020 |Batch: 000/422 |Loss: 0.6161\n",
      "Epoch: 002/020 |Batch: 150/422 |Loss: 0.8466\n",
      "Epoch: 002/020 |Batch: 300/422 |Loss: 0.4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:11<01:45,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/020\n",
      "Train Accuracy: 87.60 | Valid Accuracy: 86.08 | Test Accuracy: 87.24\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 003/020 |Batch: 000/422 |Loss: 0.4700\n",
      "Epoch: 003/020 |Batch: 150/422 |Loss: 0.5817\n",
      "Epoch: 003/020 |Batch: 300/422 |Loss: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:17<01:41,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/020\n",
      "Train Accuracy: 91.00 | Valid Accuracy: 89.62 | Test Accuracy: 90.53\n",
      "Time elapsed: 0.30 min\n",
      "Epoch: 004/020 |Batch: 000/422 |Loss: 0.3379\n",
      "Epoch: 004/020 |Batch: 150/422 |Loss: 0.4308\n",
      "Epoch: 004/020 |Batch: 300/422 |Loss: 0.6068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:23<01:36,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004/020\n",
      "Train Accuracy: 91.43 | Valid Accuracy: 90.02 | Test Accuracy: 91.06\n",
      "Time elapsed: 0.40 min\n",
      "Epoch: 005/020 |Batch: 000/422 |Loss: 0.5922\n",
      "Epoch: 005/020 |Batch: 150/422 |Loss: 0.4311\n",
      "Epoch: 005/020 |Batch: 300/422 |Loss: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:29<01:30,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005/020\n",
      "Train Accuracy: 91.15 | Valid Accuracy: 89.73 | Test Accuracy: 91.04\n",
      "Time elapsed: 0.50 min\n",
      "Epoch: 006/020 |Batch: 000/422 |Loss: 0.6778\n",
      "Epoch: 006/020 |Batch: 150/422 |Loss: 0.2696\n",
      "Epoch: 006/020 |Batch: 300/422 |Loss: 0.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:36<01:25,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006/020\n",
      "Train Accuracy: 91.00 | Valid Accuracy: 89.53 | Test Accuracy: 90.61\n",
      "Time elapsed: 0.60 min\n",
      "Epoch: 007/020 |Batch: 000/422 |Loss: 0.1388\n",
      "Epoch: 007/020 |Batch: 150/422 |Loss: 0.6064\n",
      "Epoch: 007/020 |Batch: 300/422 |Loss: 0.4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:42<01:19,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007/020\n",
      "Train Accuracy: 90.52 | Valid Accuracy: 88.93 | Test Accuracy: 90.12\n",
      "Time elapsed: 0.70 min\n",
      "Epoch: 008/020 |Batch: 000/422 |Loss: 0.4378\n",
      "Epoch: 008/020 |Batch: 150/422 |Loss: 0.6211\n",
      "Epoch: 008/020 |Batch: 300/422 |Loss: 0.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:48<01:13,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008/020\n",
      "Train Accuracy: 89.60 | Valid Accuracy: 88.18 | Test Accuracy: 89.60\n",
      "Time elapsed: 0.81 min\n",
      "Epoch: 009/020 |Batch: 000/422 |Loss: 0.5997\n",
      "Epoch: 009/020 |Batch: 150/422 |Loss: 0.3908\n",
      "Epoch: 009/020 |Batch: 300/422 |Loss: 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:54<01:07,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/020\n",
      "Train Accuracy: 91.02 | Valid Accuracy: 89.67 | Test Accuracy: 90.61\n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 010/020 |Batch: 000/422 |Loss: 0.3945\n",
      "Epoch: 010/020 |Batch: 150/422 |Loss: 0.3688\n",
      "Epoch: 010/020 |Batch: 300/422 |Loss: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:00<01:01,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010/020\n",
      "Train Accuracy: 87.15 | Valid Accuracy: 85.22 | Test Accuracy: 87.09\n",
      "Time elapsed: 1.02 min\n",
      "Epoch: 011/020 |Batch: 000/422 |Loss: 0.4646\n",
      "Epoch: 011/020 |Batch: 150/422 |Loss: 0.2534\n",
      "Epoch: 011/020 |Batch: 300/422 |Loss: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:05<01:05,  6.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3258841/113559046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mval_acc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtest_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3258841/453095122.py\u001b[0m in \u001b[0;36mcompute_acc\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnum_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch-env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3258841/3846373916.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Input: [B, N, N] x [B, N, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Output: [B, N]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mavg_neighbor_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_neighbor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "loss_list = []\n",
    "train_acc_list, val_acc_list, test_acc_list = [], [], []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward and back-propagation\n",
    "        logits, probas = model(features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        if not batch_idx % 150:\n",
    "            print(f\"Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} |\"\n",
    "                    f\"Batch: {batch_idx:03d}/{len(train_loader):03d} |\"\n",
    "                    f\"Loss: {loss:.4f}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_acc = compute_acc(model, train_loader, device)\n",
    "        val_acc   = compute_acc(model, val_loader, device)\n",
    "        test_acc  = compute_acc(model, test_loader, device)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n\"\n",
    "                f\"Train Accuracy: {train_acc:.2f} | Valid Accuracy: {val_acc:.2f} | Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"Time elapsed: {elapsed:.2f} min\")\n",
    "\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"Total Training Time: {elapsed:.2f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label='Loss')\n",
    "plt.plot(np.convolve(loss_list, np.ones(200,) / 200, mode='valid'), label='Running Average')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, NUM_EPOCHS+1), train_acc_list, label='Training')\n",
    "plt.plot(np.arange(1, NUM_EPOCHS+1), val_acc_list, label='Validation')\n",
    "plt.plot(np.arange(1, NUM_EPOCHS+1), test_acc_list, label='Testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd409492fea0b90f1e24a4fd0f416e2edfe4fabf2ed7f769ce0dd2938f1b1517"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
